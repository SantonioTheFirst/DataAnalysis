{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDA_lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B-v9KmK6bvfusNxsgQSZnaA2QuecQUYp",
      "authorship_tag": "ABX9TyNcGBL42jLUzUPVYZkLKYFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantonioTheFirst/DataAnalysis/blob/main/lab4/task1%2Btask2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKWJCW6NUr2q"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9jUVcKQXsqs"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/preprocessed.csv', header=0, compression='xz', index_col='Unnamed: 0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "ulouf5ooYGW7",
        "outputId": "03c674e5-d83c-49f0-f900-7c9d3018d888"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_left</th>\n",
              "      <th>ct_score</th>\n",
              "      <th>t_score</th>\n",
              "      <th>map</th>\n",
              "      <th>bomb_planted</th>\n",
              "      <th>ct_health</th>\n",
              "      <th>t_health</th>\n",
              "      <th>ct_armor</th>\n",
              "      <th>t_armor</th>\n",
              "      <th>ct_money</th>\n",
              "      <th>t_money</th>\n",
              "      <th>ct_helmets</th>\n",
              "      <th>t_helmets</th>\n",
              "      <th>ct_defuse_kits</th>\n",
              "      <th>ct_players_alive</th>\n",
              "      <th>t_players_alive</th>\n",
              "      <th>ct_weapon_ak47</th>\n",
              "      <th>t_weapon_ak47</th>\n",
              "      <th>ct_weapon_aug</th>\n",
              "      <th>t_weapon_aug</th>\n",
              "      <th>ct_weapon_awp</th>\n",
              "      <th>t_weapon_awp</th>\n",
              "      <th>ct_weapon_bizon</th>\n",
              "      <th>t_weapon_bizon</th>\n",
              "      <th>ct_weapon_cz75auto</th>\n",
              "      <th>t_weapon_cz75auto</th>\n",
              "      <th>ct_weapon_elite</th>\n",
              "      <th>t_weapon_elite</th>\n",
              "      <th>ct_weapon_famas</th>\n",
              "      <th>t_weapon_famas</th>\n",
              "      <th>ct_weapon_g3sg1</th>\n",
              "      <th>t_weapon_g3sg1</th>\n",
              "      <th>ct_weapon_galilar</th>\n",
              "      <th>t_weapon_galilar</th>\n",
              "      <th>ct_weapon_glock</th>\n",
              "      <th>t_weapon_glock</th>\n",
              "      <th>ct_weapon_m249</th>\n",
              "      <th>t_weapon_m249</th>\n",
              "      <th>ct_weapon_m4a1s</th>\n",
              "      <th>t_weapon_m4a1s</th>\n",
              "      <th>...</th>\n",
              "      <th>t_weapon_p90</th>\n",
              "      <th>ct_weapon_r8revolver</th>\n",
              "      <th>t_weapon_r8revolver</th>\n",
              "      <th>ct_weapon_sawedoff</th>\n",
              "      <th>t_weapon_sawedoff</th>\n",
              "      <th>ct_weapon_scar20</th>\n",
              "      <th>t_weapon_scar20</th>\n",
              "      <th>ct_weapon_sg553</th>\n",
              "      <th>t_weapon_sg553</th>\n",
              "      <th>ct_weapon_ssg08</th>\n",
              "      <th>t_weapon_ssg08</th>\n",
              "      <th>ct_weapon_ump45</th>\n",
              "      <th>t_weapon_ump45</th>\n",
              "      <th>ct_weapon_xm1014</th>\n",
              "      <th>t_weapon_xm1014</th>\n",
              "      <th>ct_weapon_deagle</th>\n",
              "      <th>t_weapon_deagle</th>\n",
              "      <th>ct_weapon_fiveseven</th>\n",
              "      <th>t_weapon_fiveseven</th>\n",
              "      <th>ct_weapon_usps</th>\n",
              "      <th>t_weapon_usps</th>\n",
              "      <th>ct_weapon_p250</th>\n",
              "      <th>t_weapon_p250</th>\n",
              "      <th>ct_weapon_p2000</th>\n",
              "      <th>t_weapon_p2000</th>\n",
              "      <th>ct_weapon_tec9</th>\n",
              "      <th>t_weapon_tec9</th>\n",
              "      <th>ct_grenade_hegrenade</th>\n",
              "      <th>t_grenade_hegrenade</th>\n",
              "      <th>ct_grenade_flashbang</th>\n",
              "      <th>t_grenade_flashbang</th>\n",
              "      <th>ct_grenade_smokegrenade</th>\n",
              "      <th>t_grenade_smokegrenade</th>\n",
              "      <th>ct_grenade_incendiarygrenade</th>\n",
              "      <th>t_grenade_incendiarygrenade</th>\n",
              "      <th>ct_grenade_molotovgrenade</th>\n",
              "      <th>t_grenade_molotovgrenade</th>\n",
              "      <th>ct_grenade_decoygrenade</th>\n",
              "      <th>t_grenade_decoygrenade</th>\n",
              "      <th>round_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.415828</td>\n",
              "      <td>-1.400576</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>0.695301</td>\n",
              "      <td>-1.836777</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>-0.516186</td>\n",
              "      <td>-0.595345</td>\n",
              "      <td>-1.115364</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-1.004951</td>\n",
              "      <td>0.602448</td>\n",
              "      <td>0.597412</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>-0.283147</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>1.039382</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>-0.224726</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-1.045338</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.886648</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.067531</td>\n",
              "      <td>-1.400576</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>0.695301</td>\n",
              "      <td>0.502008</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>-0.819351</td>\n",
              "      <td>-0.870776</td>\n",
              "      <td>-1.115364</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-0.382199</td>\n",
              "      <td>0.602448</td>\n",
              "      <td>0.597412</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>-0.283147</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>1.039382</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>-0.224726</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-1.045338</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.886648</td>\n",
              "      <td>0.203841</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.034094</td>\n",
              "      <td>-1.400576</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>-0.159544</td>\n",
              "      <td>-0.019401</td>\n",
              "      <td>-0.117770</td>\n",
              "      <td>-0.563908</td>\n",
              "      <td>-0.805977</td>\n",
              "      <td>-0.883109</td>\n",
              "      <td>-1.115364</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-0.382199</td>\n",
              "      <td>-0.227087</td>\n",
              "      <td>-0.216709</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>-0.283147</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>0.424292</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>-0.224726</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>-0.409385</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-1.045338</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.886648</td>\n",
              "      <td>0.203841</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.401302</td>\n",
              "      <td>-1.400576</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>-0.159544</td>\n",
              "      <td>-0.019401</td>\n",
              "      <td>-0.117770</td>\n",
              "      <td>-0.563908</td>\n",
              "      <td>-0.805977</td>\n",
              "      <td>-0.883109</td>\n",
              "      <td>-1.115364</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-0.382199</td>\n",
              "      <td>-0.227087</td>\n",
              "      <td>-0.216709</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>-0.283147</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>-0.190798</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>-0.224726</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>-0.409385</td>\n",
              "      <td>13.301747</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-1.045338</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.886648</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.415277</td>\n",
              "      <td>-1.191823</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>0.695301</td>\n",
              "      <td>-0.714160</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>0.763351</td>\n",
              "      <td>-0.040372</td>\n",
              "      <td>-1.115364</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-0.382199</td>\n",
              "      <td>0.602448</td>\n",
              "      <td>0.597412</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>-0.283147</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>1.039382</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>-0.224726</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-1.045338</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.886648</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.313652</td>\n",
              "      <td>-1.191823</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>0.695301</td>\n",
              "      <td>1.086704</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>-0.716810</td>\n",
              "      <td>-0.056816</td>\n",
              "      <td>1.599869</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-0.382199</td>\n",
              "      <td>0.602448</td>\n",
              "      <td>0.597412</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>7.429369</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>1.039382</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>3.551865</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>4.144799</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>1.639325</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>0.646916</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>0.839676</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.001350</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.053556</td>\n",
              "      <td>-1.191823</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>-0.885208</td>\n",
              "      <td>-2.084889</td>\n",
              "      <td>-0.106076</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>-0.721269</td>\n",
              "      <td>-0.513127</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-1.004951</td>\n",
              "      <td>-1.056621</td>\n",
              "      <td>-1.844949</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>2.287692</td>\n",
              "      <td>14.061329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>-0.805888</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>3.551865</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>4.144799</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>-0.743511</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>0.082832</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.311206</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.420764</td>\n",
              "      <td>-1.191823</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>-0.885208</td>\n",
              "      <td>-2.084889</td>\n",
              "      <td>-0.106076</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>-0.721269</td>\n",
              "      <td>-0.513127</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-1.004951</td>\n",
              "      <td>-1.056621</td>\n",
              "      <td>-1.844949</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>2.287692</td>\n",
              "      <td>14.061329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>-0.805888</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>3.551865</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>4.144799</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>-0.743511</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>0.082832</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.311206</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.787972</td>\n",
              "      <td>-1.191823</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>-1.232921</td>\n",
              "      <td>-2.242124</td>\n",
              "      <td>-0.263944</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>-0.667769</td>\n",
              "      <td>-0.681674</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-1.004951</td>\n",
              "      <td>-1.056621</td>\n",
              "      <td>-2.659069</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>2.287692</td>\n",
              "      <td>14.061329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>-1.420978</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>3.551865</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>4.144799</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>-0.743511</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>0.082832</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.311206</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.415277</td>\n",
              "      <td>-0.983069</td>\n",
              "      <td>-1.405702</td>\n",
              "      <td>0.664386</td>\n",
              "      <td>0.695301</td>\n",
              "      <td>-0.690772</td>\n",
              "      <td>-1.709542</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>1.003799</td>\n",
              "      <td>-0.029271</td>\n",
              "      <td>-1.379297</td>\n",
              "      <td>-1.004951</td>\n",
              "      <td>0.602448</td>\n",
              "      <td>0.597412</td>\n",
              "      <td>-0.470136</td>\n",
              "      <td>-0.912049</td>\n",
              "      <td>-0.292446</td>\n",
              "      <td>-0.083519</td>\n",
              "      <td>-0.852132</td>\n",
              "      <td>-0.67383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009039</td>\n",
              "      <td>-0.340853</td>\n",
              "      <td>-0.279094</td>\n",
              "      <td>-0.063461</td>\n",
              "      <td>-0.042141</td>\n",
              "      <td>2.287692</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.098501</td>\n",
              "      <td>-0.271725</td>\n",
              "      <td>-0.079592</td>\n",
              "      <td>1.039382</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.242763</td>\n",
              "      <td>-0.051389</td>\n",
              "      <td>-0.882806</td>\n",
              "      <td>-0.213485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011785</td>\n",
              "      <td>-0.026822</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.431618</td>\n",
              "      <td>-0.723924</td>\n",
              "      <td>3.551865</td>\n",
              "      <td>-0.139955</td>\n",
              "      <td>-0.201795</td>\n",
              "      <td>-0.172652</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.01617</td>\n",
              "      <td>-0.528063</td>\n",
              "      <td>-0.467479</td>\n",
              "      <td>-0.214046</td>\n",
              "      <td>-0.093784</td>\n",
              "      <td>0.516902</td>\n",
              "      <td>-0.278862</td>\n",
              "      <td>-0.44395</td>\n",
              "      <td>-0.503436</td>\n",
              "      <td>1.942778</td>\n",
              "      <td>-0.065959</td>\n",
              "      <td>-0.085586</td>\n",
              "      <td>-0.147871</td>\n",
              "      <td>-0.701566</td>\n",
              "      <td>-0.542299</td>\n",
              "      <td>-0.481253</td>\n",
              "      <td>-1.035461</td>\n",
              "      <td>-0.311206</td>\n",
              "      <td>-0.889569</td>\n",
              "      <td>-0.687185</td>\n",
              "      <td>-0.137694</td>\n",
              "      <td>-0.210881</td>\n",
              "      <td>-0.812929</td>\n",
              "      <td>-0.163356</td>\n",
              "      <td>-0.156855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 97 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   time_left  ct_score  ...  t_grenade_decoygrenade  round_winner\n",
              "0   1.415828 -1.400576  ...                     0.0            CT\n",
              "1   1.067531 -1.400576  ...                     0.0            CT\n",
              "2  -0.034094 -1.400576  ...                     0.0            CT\n",
              "3  -0.401302 -1.400576  ...                     0.0            CT\n",
              "4   1.415277 -1.191823  ...                     0.0            CT\n",
              "5   0.313652 -1.191823  ...                     0.0            CT\n",
              "6  -0.053556 -1.191823  ...                     0.0            CT\n",
              "7  -0.420764 -1.191823  ...                     0.0            CT\n",
              "8  -0.787972 -1.191823  ...                     0.0            CT\n",
              "9   1.415277 -0.983069  ...                     0.0            CT\n",
              "\n",
              "[10 rows x 97 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3BTux3aXYIyV",
        "outputId": "e8589690-aae9-4d78-88f8-74131be88879"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_left</th>\n",
              "      <th>ct_score</th>\n",
              "      <th>t_score</th>\n",
              "      <th>map</th>\n",
              "      <th>bomb_planted</th>\n",
              "      <th>ct_health</th>\n",
              "      <th>t_health</th>\n",
              "      <th>ct_armor</th>\n",
              "      <th>t_armor</th>\n",
              "      <th>ct_money</th>\n",
              "      <th>t_money</th>\n",
              "      <th>ct_helmets</th>\n",
              "      <th>t_helmets</th>\n",
              "      <th>ct_defuse_kits</th>\n",
              "      <th>ct_players_alive</th>\n",
              "      <th>t_players_alive</th>\n",
              "      <th>ct_weapon_ak47</th>\n",
              "      <th>t_weapon_ak47</th>\n",
              "      <th>ct_weapon_aug</th>\n",
              "      <th>t_weapon_aug</th>\n",
              "      <th>ct_weapon_awp</th>\n",
              "      <th>t_weapon_awp</th>\n",
              "      <th>ct_weapon_bizon</th>\n",
              "      <th>t_weapon_bizon</th>\n",
              "      <th>ct_weapon_cz75auto</th>\n",
              "      <th>t_weapon_cz75auto</th>\n",
              "      <th>ct_weapon_elite</th>\n",
              "      <th>t_weapon_elite</th>\n",
              "      <th>ct_weapon_famas</th>\n",
              "      <th>t_weapon_famas</th>\n",
              "      <th>ct_weapon_g3sg1</th>\n",
              "      <th>t_weapon_g3sg1</th>\n",
              "      <th>ct_weapon_galilar</th>\n",
              "      <th>t_weapon_galilar</th>\n",
              "      <th>ct_weapon_glock</th>\n",
              "      <th>t_weapon_glock</th>\n",
              "      <th>ct_weapon_m249</th>\n",
              "      <th>t_weapon_m249</th>\n",
              "      <th>ct_weapon_m4a1s</th>\n",
              "      <th>t_weapon_m4a1s</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_weapon_p90</th>\n",
              "      <th>t_weapon_p90</th>\n",
              "      <th>ct_weapon_r8revolver</th>\n",
              "      <th>t_weapon_r8revolver</th>\n",
              "      <th>ct_weapon_sawedoff</th>\n",
              "      <th>t_weapon_sawedoff</th>\n",
              "      <th>ct_weapon_scar20</th>\n",
              "      <th>t_weapon_scar20</th>\n",
              "      <th>ct_weapon_sg553</th>\n",
              "      <th>t_weapon_sg553</th>\n",
              "      <th>ct_weapon_ssg08</th>\n",
              "      <th>t_weapon_ssg08</th>\n",
              "      <th>ct_weapon_ump45</th>\n",
              "      <th>t_weapon_ump45</th>\n",
              "      <th>ct_weapon_xm1014</th>\n",
              "      <th>t_weapon_xm1014</th>\n",
              "      <th>ct_weapon_deagle</th>\n",
              "      <th>t_weapon_deagle</th>\n",
              "      <th>ct_weapon_fiveseven</th>\n",
              "      <th>t_weapon_fiveseven</th>\n",
              "      <th>ct_weapon_usps</th>\n",
              "      <th>t_weapon_usps</th>\n",
              "      <th>ct_weapon_p250</th>\n",
              "      <th>t_weapon_p250</th>\n",
              "      <th>ct_weapon_p2000</th>\n",
              "      <th>t_weapon_p2000</th>\n",
              "      <th>ct_weapon_tec9</th>\n",
              "      <th>t_weapon_tec9</th>\n",
              "      <th>ct_grenade_hegrenade</th>\n",
              "      <th>t_grenade_hegrenade</th>\n",
              "      <th>ct_grenade_flashbang</th>\n",
              "      <th>t_grenade_flashbang</th>\n",
              "      <th>ct_grenade_smokegrenade</th>\n",
              "      <th>t_grenade_smokegrenade</th>\n",
              "      <th>ct_grenade_incendiarygrenade</th>\n",
              "      <th>t_grenade_incendiarygrenade</th>\n",
              "      <th>ct_grenade_molotovgrenade</th>\n",
              "      <th>t_grenade_molotovgrenade</th>\n",
              "      <th>ct_grenade_decoygrenade</th>\n",
              "      <th>t_grenade_decoygrenade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>122410.0</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>122410.0</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>122410.0</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>122410.0</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>122410.0</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>1.224100e+05</td>\n",
              "      <td>122410.000000</td>\n",
              "      <td>122410.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-4.288946e-15</td>\n",
              "      <td>1.444837e-15</td>\n",
              "      <td>1.031806e-16</td>\n",
              "      <td>-3.982250e-15</td>\n",
              "      <td>1.310298e-14</td>\n",
              "      <td>6.196298e-16</td>\n",
              "      <td>-3.250783e-16</td>\n",
              "      <td>9.602799e-16</td>\n",
              "      <td>4.941064e-16</td>\n",
              "      <td>-1.999182e-15</td>\n",
              "      <td>4.433966e-15</td>\n",
              "      <td>4.512372e-15</td>\n",
              "      <td>8.059253e-15</td>\n",
              "      <td>6.020607e-15</td>\n",
              "      <td>3.752859e-14</td>\n",
              "      <td>-1.313554e-13</td>\n",
              "      <td>-5.484578e-14</td>\n",
              "      <td>1.591783e-14</td>\n",
              "      <td>2.072543e-14</td>\n",
              "      <td>-8.392321e-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.969661e-15</td>\n",
              "      <td>-4.975392e-15</td>\n",
              "      <td>2.426783e-14</td>\n",
              "      <td>-1.289328e-14</td>\n",
              "      <td>-1.179309e-14</td>\n",
              "      <td>-9.396835e-15</td>\n",
              "      <td>3.039353e-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.671845e-15</td>\n",
              "      <td>7.822238e-17</td>\n",
              "      <td>-6.036948e-15</td>\n",
              "      <td>2.014328e-15</td>\n",
              "      <td>-1.059221e-14</td>\n",
              "      <td>-4.332365e-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.171959e-14</td>\n",
              "      <td>5.608958e-15</td>\n",
              "      <td>5.317876e-14</td>\n",
              "      <td>-8.296649e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.880275e-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.257634e-14</td>\n",
              "      <td>1.386790e-14</td>\n",
              "      <td>-4.332829e-15</td>\n",
              "      <td>-8.531787e-14</td>\n",
              "      <td>1.026473e-13</td>\n",
              "      <td>2.051830e-14</td>\n",
              "      <td>-3.722903e-15</td>\n",
              "      <td>-2.389034e-15</td>\n",
              "      <td>1.088973e-14</td>\n",
              "      <td>1.758632e-14</td>\n",
              "      <td>-1.097471e-14</td>\n",
              "      <td>3.969766e-15</td>\n",
              "      <td>5.050164e-15</td>\n",
              "      <td>1.595003e-14</td>\n",
              "      <td>4.911342e-15</td>\n",
              "      <td>4.324666e-15</td>\n",
              "      <td>2.918422e-15</td>\n",
              "      <td>2.866921e-15</td>\n",
              "      <td>3.212743e-15</td>\n",
              "      <td>6.927636e-14</td>\n",
              "      <td>-3.890309e-15</td>\n",
              "      <td>-6.753036e-14</td>\n",
              "      <td>-3.989584e-15</td>\n",
              "      <td>-4.662043e-15</td>\n",
              "      <td>-4.906734e-15</td>\n",
              "      <td>3.183941e-15</td>\n",
              "      <td>-8.777591e-16</td>\n",
              "      <td>-1.321889e-14</td>\n",
              "      <td>1.317659e-14</td>\n",
              "      <td>3.834698e-15</td>\n",
              "      <td>6.439392e-15</td>\n",
              "      <td>-4.421712e-14</td>\n",
              "      <td>8.135692e-15</td>\n",
              "      <td>3.013521e-15</td>\n",
              "      <td>-4.397655e-15</td>\n",
              "      <td>3.520170</td>\n",
              "      <td>0.111788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.000004e+00</td>\n",
              "      <td>1.929088</td>\n",
              "      <td>0.315107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.797060e+00</td>\n",
              "      <td>-1.400576e+00</td>\n",
              "      <td>-1.405702e+00</td>\n",
              "      <td>-3.115111e+00</td>\n",
              "      <td>-2.878208e+00</td>\n",
              "      <td>-1.836777e+00</td>\n",
              "      <td>-1.709542e+00</td>\n",
              "      <td>-8.728513e-01</td>\n",
              "      <td>-9.242178e-01</td>\n",
              "      <td>-1.115364e+00</td>\n",
              "      <td>-1.379297e+00</td>\n",
              "      <td>-1.004951e+00</td>\n",
              "      <td>-3.545225e+00</td>\n",
              "      <td>-3.473189e+00</td>\n",
              "      <td>-4.701360e-01</td>\n",
              "      <td>-9.120488e-01</td>\n",
              "      <td>-2.924461e-01</td>\n",
              "      <td>-8.351861e-02</td>\n",
              "      <td>-8.521318e-01</td>\n",
              "      <td>-6.738296e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.038769e-03</td>\n",
              "      <td>-3.408535e-01</td>\n",
              "      <td>-2.790942e-01</td>\n",
              "      <td>-6.346073e-02</td>\n",
              "      <td>-4.214118e-02</td>\n",
              "      <td>-2.831472e-01</td>\n",
              "      <td>-6.694222e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.133137e-02</td>\n",
              "      <td>-9.850073e-02</td>\n",
              "      <td>-2.717247e-01</td>\n",
              "      <td>-7.959236e-02</td>\n",
              "      <td>-2.036068e+00</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.427631e-01</td>\n",
              "      <td>-5.138930e-02</td>\n",
              "      <td>-8.828062e-01</td>\n",
              "      <td>-2.134853e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.562284e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.178545e-02</td>\n",
              "      <td>-2.682187e-02</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>-4.316183e-01</td>\n",
              "      <td>-7.239244e-01</td>\n",
              "      <td>-2.247258e-01</td>\n",
              "      <td>-1.399546e-01</td>\n",
              "      <td>-2.017947e-01</td>\n",
              "      <td>-1.726519e-01</td>\n",
              "      <td>-8.577666e-02</td>\n",
              "      <td>-1.617049e-02</td>\n",
              "      <td>-5.280625e-01</td>\n",
              "      <td>-4.674791e-01</td>\n",
              "      <td>-2.140458e-01</td>\n",
              "      <td>-9.378390e-02</td>\n",
              "      <td>-2.003924e+00</td>\n",
              "      <td>-2.788625e-01</td>\n",
              "      <td>-4.439504e-01</td>\n",
              "      <td>-5.034363e-01</td>\n",
              "      <td>-4.093851e-01</td>\n",
              "      <td>-6.595944e-02</td>\n",
              "      <td>-8.558571e-02</td>\n",
              "      <td>-1.478711e-01</td>\n",
              "      <td>-7.015660e-01</td>\n",
              "      <td>-5.422993e-01</td>\n",
              "      <td>-1.045338e+00</td>\n",
              "      <td>-1.035461e+00</td>\n",
              "      <td>-8.866477e-01</td>\n",
              "      <td>-8.895692e-01</td>\n",
              "      <td>-6.871847e-01</td>\n",
              "      <td>-1.376939e-01</td>\n",
              "      <td>-2.108807e-01</td>\n",
              "      <td>-8.129290e-01</td>\n",
              "      <td>-1.633564e-01</td>\n",
              "      <td>-1.568546e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.888903e-01</td>\n",
              "      <td>-7.743161e-01</td>\n",
              "      <td>-7.837496e-01</td>\n",
              "      <td>-4.694631e-01</td>\n",
              "      <td>-5.768681e-01</td>\n",
              "      <td>-7.024662e-01</td>\n",
              "      <td>-7.128402e-01</td>\n",
              "      <td>-7.569350e-01</td>\n",
              "      <td>-7.967796e-01</td>\n",
              "      <td>-1.115364e+00</td>\n",
              "      <td>-1.379297e+00</td>\n",
              "      <td>-1.004951e+00</td>\n",
              "      <td>-2.270868e-01</td>\n",
              "      <td>-2.167085e-01</td>\n",
              "      <td>-4.701360e-01</td>\n",
              "      <td>-9.120488e-01</td>\n",
              "      <td>-2.924461e-01</td>\n",
              "      <td>-8.351861e-02</td>\n",
              "      <td>-8.521318e-01</td>\n",
              "      <td>-6.738296e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.038769e-03</td>\n",
              "      <td>-3.408535e-01</td>\n",
              "      <td>-2.790942e-01</td>\n",
              "      <td>-6.346073e-02</td>\n",
              "      <td>-4.214118e-02</td>\n",
              "      <td>-2.831472e-01</td>\n",
              "      <td>-6.694222e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.133137e-02</td>\n",
              "      <td>-9.850073e-02</td>\n",
              "      <td>-2.717247e-01</td>\n",
              "      <td>-7.959236e-02</td>\n",
              "      <td>-8.058881e-01</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.427631e-01</td>\n",
              "      <td>-5.138930e-02</td>\n",
              "      <td>-8.828062e-01</td>\n",
              "      <td>-2.134853e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.562284e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.178545e-02</td>\n",
              "      <td>-2.682187e-02</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>-4.316183e-01</td>\n",
              "      <td>-7.239244e-01</td>\n",
              "      <td>-2.247258e-01</td>\n",
              "      <td>-1.399546e-01</td>\n",
              "      <td>-2.017947e-01</td>\n",
              "      <td>-1.726519e-01</td>\n",
              "      <td>-8.577666e-02</td>\n",
              "      <td>-1.617049e-02</td>\n",
              "      <td>-5.280625e-01</td>\n",
              "      <td>-4.674791e-01</td>\n",
              "      <td>-2.140458e-01</td>\n",
              "      <td>-9.378390e-02</td>\n",
              "      <td>-7.435108e-01</td>\n",
              "      <td>-2.788625e-01</td>\n",
              "      <td>-4.439504e-01</td>\n",
              "      <td>-5.034363e-01</td>\n",
              "      <td>-4.093851e-01</td>\n",
              "      <td>-6.595944e-02</td>\n",
              "      <td>-8.558571e-02</td>\n",
              "      <td>-1.478711e-01</td>\n",
              "      <td>-7.015660e-01</td>\n",
              "      <td>-5.422993e-01</td>\n",
              "      <td>-1.045338e+00</td>\n",
              "      <td>-1.035461e+00</td>\n",
              "      <td>-8.866477e-01</td>\n",
              "      <td>-8.895692e-01</td>\n",
              "      <td>-6.871847e-01</td>\n",
              "      <td>-1.376939e-01</td>\n",
              "      <td>-2.108807e-01</td>\n",
              "      <td>-8.129290e-01</td>\n",
              "      <td>-1.633564e-01</td>\n",
              "      <td>-1.568546e-01</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-5.465751e-02</td>\n",
              "      <td>-1.480561e-01</td>\n",
              "      <td>-1.617976e-01</td>\n",
              "      <td>6.643859e-01</td>\n",
              "      <td>6.953014e-01</td>\n",
              "      <td>3.675275e-01</td>\n",
              "      <td>2.036670e-01</td>\n",
              "      <td>-3.824365e-01</td>\n",
              "      <td>-3.363577e-01</td>\n",
              "      <td>-2.927066e-02</td>\n",
              "      <td>1.125673e-01</td>\n",
              "      <td>-3.821985e-01</td>\n",
              "      <td>6.024476e-01</td>\n",
              "      <td>5.974116e-01</td>\n",
              "      <td>-4.701360e-01</td>\n",
              "      <td>-1.788471e-01</td>\n",
              "      <td>-2.924461e-01</td>\n",
              "      <td>-8.351861e-02</td>\n",
              "      <td>-8.521318e-01</td>\n",
              "      <td>-6.738296e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.038769e-03</td>\n",
              "      <td>-3.408535e-01</td>\n",
              "      <td>-2.790942e-01</td>\n",
              "      <td>-6.346073e-02</td>\n",
              "      <td>-4.214118e-02</td>\n",
              "      <td>-2.831472e-01</td>\n",
              "      <td>-6.694222e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.133137e-02</td>\n",
              "      <td>-9.850073e-02</td>\n",
              "      <td>-2.717247e-01</td>\n",
              "      <td>-7.959236e-02</td>\n",
              "      <td>4.242920e-01</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.427631e-01</td>\n",
              "      <td>-5.138930e-02</td>\n",
              "      <td>-6.253395e-02</td>\n",
              "      <td>-2.134853e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.562284e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.178545e-02</td>\n",
              "      <td>-2.682187e-02</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>-4.316183e-01</td>\n",
              "      <td>-7.239244e-01</td>\n",
              "      <td>-2.247258e-01</td>\n",
              "      <td>-1.399546e-01</td>\n",
              "      <td>-2.017947e-01</td>\n",
              "      <td>-1.726519e-01</td>\n",
              "      <td>-8.577666e-02</td>\n",
              "      <td>-1.617049e-02</td>\n",
              "      <td>-5.280625e-01</td>\n",
              "      <td>-4.674791e-01</td>\n",
              "      <td>-2.140458e-01</td>\n",
              "      <td>-9.378390e-02</td>\n",
              "      <td>-1.133043e-01</td>\n",
              "      <td>-2.788625e-01</td>\n",
              "      <td>-4.439504e-01</td>\n",
              "      <td>-5.034363e-01</td>\n",
              "      <td>-4.093851e-01</td>\n",
              "      <td>-6.595944e-02</td>\n",
              "      <td>-8.558571e-02</td>\n",
              "      <td>-1.478711e-01</td>\n",
              "      <td>-7.015660e-01</td>\n",
              "      <td>-5.422993e-01</td>\n",
              "      <td>-4.812530e-01</td>\n",
              "      <td>-4.781925e-01</td>\n",
              "      <td>-3.112065e-01</td>\n",
              "      <td>-3.428641e-01</td>\n",
              "      <td>-6.871847e-01</td>\n",
              "      <td>-1.376939e-01</td>\n",
              "      <td>-2.108807e-01</td>\n",
              "      <td>-2.116926e-01</td>\n",
              "      <td>-1.633564e-01</td>\n",
              "      <td>-1.568546e-01</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.267430e+00</td>\n",
              "      <td>6.869572e-01</td>\n",
              "      <td>6.674717e-01</td>\n",
              "      <td>6.643859e-01</td>\n",
              "      <td>6.953014e-01</td>\n",
              "      <td>1.004846e+00</td>\n",
              "      <td>9.712417e-01</td>\n",
              "      <td>4.289771e-01</td>\n",
              "      <td>5.557098e-01</td>\n",
              "      <td>1.056823e+00</td>\n",
              "      <td>1.107144e+00</td>\n",
              "      <td>8.633069e-01</td>\n",
              "      <td>6.024476e-01</td>\n",
              "      <td>5.974116e-01</td>\n",
              "      <td>-4.701360e-01</td>\n",
              "      <td>5.543547e-01</td>\n",
              "      <td>-2.924461e-01</td>\n",
              "      <td>-8.351861e-02</td>\n",
              "      <td>6.332077e-01</td>\n",
              "      <td>1.424079e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.038769e-03</td>\n",
              "      <td>-3.408535e-01</td>\n",
              "      <td>-2.790942e-01</td>\n",
              "      <td>-6.346073e-02</td>\n",
              "      <td>-4.214118e-02</td>\n",
              "      <td>-2.831472e-01</td>\n",
              "      <td>-6.694222e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.133137e-02</td>\n",
              "      <td>-9.850073e-02</td>\n",
              "      <td>-2.717247e-01</td>\n",
              "      <td>-7.959236e-02</td>\n",
              "      <td>1.039382e+00</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.427631e-01</td>\n",
              "      <td>-5.138930e-02</td>\n",
              "      <td>7.577383e-01</td>\n",
              "      <td>-2.134853e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.562284e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.178545e-02</td>\n",
              "      <td>-2.682187e-02</td>\n",
              "      <td>-2.858205e-03</td>\n",
              "      <td>-4.316183e-01</td>\n",
              "      <td>1.536227e-01</td>\n",
              "      <td>-2.247258e-01</td>\n",
              "      <td>-1.399546e-01</td>\n",
              "      <td>-2.017947e-01</td>\n",
              "      <td>-1.726519e-01</td>\n",
              "      <td>-8.577666e-02</td>\n",
              "      <td>-1.617049e-02</td>\n",
              "      <td>6.702419e-01</td>\n",
              "      <td>-4.674791e-01</td>\n",
              "      <td>-2.140458e-01</td>\n",
              "      <td>-9.378390e-02</td>\n",
              "      <td>1.147109e+00</td>\n",
              "      <td>-2.788625e-01</td>\n",
              "      <td>-4.439504e-01</td>\n",
              "      <td>-5.034363e-01</td>\n",
              "      <td>-4.093851e-01</td>\n",
              "      <td>-6.595944e-02</td>\n",
              "      <td>-8.558571e-02</td>\n",
              "      <td>-1.478711e-01</td>\n",
              "      <td>7.873088e-02</td>\n",
              "      <td>6.951018e-01</td>\n",
              "      <td>6.469162e-01</td>\n",
              "      <td>6.363456e-01</td>\n",
              "      <td>8.396760e-01</td>\n",
              "      <td>7.505459e-01</td>\n",
              "      <td>6.844842e-01</td>\n",
              "      <td>-1.376939e-01</td>\n",
              "      <td>-2.108807e-01</td>\n",
              "      <td>3.895438e-01</td>\n",
              "      <td>-1.633564e-01</td>\n",
              "      <td>-1.568546e-01</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.415828e+00</td>\n",
              "      <td>5.279530e+00</td>\n",
              "      <td>5.435770e+00</td>\n",
              "      <td>6.643859e-01</td>\n",
              "      <td>1.410003e+00</td>\n",
              "      <td>1.086704e+00</td>\n",
              "      <td>1.154543e+00</td>\n",
              "      <td>6.260455e+00</td>\n",
              "      <td>5.653238e+00</td>\n",
              "      <td>1.599869e+00</td>\n",
              "      <td>1.107144e+00</td>\n",
              "      <td>2.108812e+00</td>\n",
              "      <td>6.024476e-01</td>\n",
              "      <td>1.411532e+00</td>\n",
              "      <td>6.378123e+00</td>\n",
              "      <td>2.753960e+00</td>\n",
              "      <td>1.057002e+01</td>\n",
              "      <td>3.271920e+01</td>\n",
              "      <td>6.574566e+00</td>\n",
              "      <td>7.717806e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.106345e+02</td>\n",
              "      <td>1.087223e+01</td>\n",
              "      <td>1.551073e+01</td>\n",
              "      <td>1.575778e+01</td>\n",
              "      <td>2.372976e+01</td>\n",
              "      <td>1.257105e+01</td>\n",
              "      <td>2.818960e+01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.076559e+02</td>\n",
              "      <td>1.773800e+01</td>\n",
              "      <td>1.204564e+01</td>\n",
              "      <td>3.442891e+01</td>\n",
              "      <td>3.499742e+00</td>\n",
              "      <td>3.498700e+02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.116915e+01</td>\n",
              "      <td>3.761666e+01</td>\n",
              "      <td>3.218555e+00</td>\n",
              "      <td>1.193186e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.322352e+02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.485039e+01</td>\n",
              "      <td>3.728301e+01</td>\n",
              "      <td>3.498700e+02</td>\n",
              "      <td>6.787674e+00</td>\n",
              "      <td>3.663811e+00</td>\n",
              "      <td>1.488164e+01</td>\n",
              "      <td>2.040182e+01</td>\n",
              "      <td>1.283799e+01</td>\n",
              "      <td>1.403052e+01</td>\n",
              "      <td>2.261676e+01</td>\n",
              "      <td>6.184103e+01</td>\n",
              "      <td>5.463460e+00</td>\n",
              "      <td>5.669551e+00</td>\n",
              "      <td>1.711718e+01</td>\n",
              "      <td>1.988896e+01</td>\n",
              "      <td>4.298141e+00</td>\n",
              "      <td>1.111257e+01</td>\n",
              "      <td>8.923115e+00</td>\n",
              "      <td>8.128331e+00</td>\n",
              "      <td>6.647103e+00</td>\n",
              "      <td>4.003716e+01</td>\n",
              "      <td>2.099398e+01</td>\n",
              "      <td>2.073578e+01</td>\n",
              "      <td>3.199918e+00</td>\n",
              "      <td>5.644706e+00</td>\n",
              "      <td>2.903255e+00</td>\n",
              "      <td>2.865422e+00</td>\n",
              "      <td>2.566000e+00</td>\n",
              "      <td>4.030776e+00</td>\n",
              "      <td>2.741988e+00</td>\n",
              "      <td>2.070539e+01</td>\n",
              "      <td>1.296620e+01</td>\n",
              "      <td>2.193253e+00</td>\n",
              "      <td>1.753262e+01</td>\n",
              "      <td>1.202625e+01</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          time_left  ...  t_grenade_decoygrenade\n",
              "count  1.224100e+05  ...           122410.000000\n",
              "mean  -4.288946e-15  ...                0.111788\n",
              "std    1.000004e+00  ...                0.315107\n",
              "min   -1.797060e+00  ...                0.000000\n",
              "25%   -7.888903e-01  ...                0.000000\n",
              "50%   -5.465751e-02  ...                0.000000\n",
              "75%    1.267430e+00  ...                0.000000\n",
              "max    1.415828e+00  ...                1.000000\n",
              "\n",
              "[8 rows x 96 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPByn83PYVua"
      },
      "source": [
        "X = df.drop(columns=['round_winner'])\n",
        "y = df[['round_winner']]\n",
        "test_size = int(0.2 * df.shape[0])\n",
        "val_size = int(0.2 * df.shape[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bboCER5rf9XA",
        "outputId": "3b9b8eb4-190b-4f8e-e60b-6947d9b5ed0c"
      },
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(73446, 96) (24482, 96) (24482, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1o4oZtgJAv"
      },
      "source": [
        "enc = OneHotEncoder(sparse=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGPhwgoBhgjS"
      },
      "source": [
        "y_train = enc.fit_transform(np.array(y_train))\n",
        "y_val = enc.transform(np.array(y_val))\n",
        "y_test = enc.transform(np.array(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8prLlJ4hqAF",
        "outputId": "328b207a-8d80-40c1-b6a7-dc7c2c9bc881"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73446, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIAkMcWZYcJ_",
        "outputId": "6e09b4c7-6d7a-4b26-b6d3-dfbdac99b2f7"
      },
      "source": [
        "X.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96,)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpzPIAPBW0Z0"
      },
      "source": [
        "# Задание класификации на данных из 2й лабы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZGi5YdGWMew"
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(Input(shape=X.shape[1:]))\n",
        "model.add(Dense(256, activation='relu', input_shape=X.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrduXH8bZwb7",
        "outputId": "dda327cb-a1f8-49f0-f557-eef1500cb9ee"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 256)               24832     \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,218\n",
            "Trainable params: 422,658\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWrTrszJcCG9"
      },
      "source": [
        "labels = {'1': 'CT', '0': 'T'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xpIVKnecNLf"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-2),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdiDHOAqcn3h"
      },
      "source": [
        "es = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)\n",
        "mch = ModelCheckpoint('best_model.h5', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHASIZyAll4I",
        "outputId": "dfab8d79-d52f-4c1f-8ac3-3a0bce8844a1"
      },
      "source": [
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    callbacks=[es, mch],\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1148/1148 [==============================] - 11s 9ms/step - loss: 0.5140 - accuracy: 0.7334 - val_loss: 0.4829 - val_accuracy: 0.7442\n",
            "Epoch 2/100\n",
            "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4652 - accuracy: 0.7487 - val_loss: 0.4662 - val_accuracy: 0.7419\n",
            "Epoch 3/100\n",
            "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4581 - accuracy: 0.7534 - val_loss: 0.4681 - val_accuracy: 0.7406\n",
            "Epoch 4/100\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.4551 - accuracy: 0.7585 - val_loss: 0.4806 - val_accuracy: 0.7395\n",
            "Epoch 5/100\n",
            "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4520 - accuracy: 0.7602 - val_loss: 0.4701 - val_accuracy: 0.7330\n",
            "Epoch 6/100\n",
            "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4456 - accuracy: 0.7622 - val_loss: 0.4629 - val_accuracy: 0.7426\n",
            "Epoch 7/100\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.4435 - accuracy: 0.7659 - val_loss: 0.4954 - val_accuracy: 0.7363\n",
            "Epoch 8/100\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.4374 - accuracy: 0.7717 - val_loss: 0.5303 - val_accuracy: 0.7389\n",
            "Epoch 9/100\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.4320 - accuracy: 0.7735 - val_loss: 0.4849 - val_accuracy: 0.7393\n",
            "Epoch 10/100\n",
            "1148/1148 [==============================] - 10s 9ms/step - loss: 0.4293 - accuracy: 0.7753 - val_loss: 0.4751 - val_accuracy: 0.7446\n",
            "Epoch 11/100\n",
            "1148/1148 [==============================] - 10s 8ms/step - loss: 0.4239 - accuracy: 0.7810 - val_loss: 0.4701 - val_accuracy: 0.7447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzALvE3snzY7",
        "outputId": "8cb13ff6-ed9d-4ea2-de49-74e34b04c6b3"
      },
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "766/766 [==============================] - 3s 4ms/step - loss: 0.4705 - accuracy: 0.7392\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47048482298851013, 0.7391961216926575]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV8dKlJapUeY",
        "outputId": "d69b274d-e425-48e2-c5b7-53e31ce02341"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.7333687543869019,\n",
              "  0.7487269639968872,\n",
              "  0.7533562183380127,\n",
              "  0.7584620118141174,\n",
              "  0.7601911425590515,\n",
              "  0.7622062563896179,\n",
              "  0.7659368515014648,\n",
              "  0.7716962099075317,\n",
              "  0.7734525799751282,\n",
              "  0.7752634882926941,\n",
              "  0.7809955477714539],\n",
              " 'loss': [0.513991117477417,\n",
              "  0.4652288258075714,\n",
              "  0.4580995440483093,\n",
              "  0.45511922240257263,\n",
              "  0.4519939124584198,\n",
              "  0.4456091523170471,\n",
              "  0.4434950351715088,\n",
              "  0.4373917281627655,\n",
              "  0.4319920539855957,\n",
              "  0.4292964041233063,\n",
              "  0.4239126145839691],\n",
              " 'val_accuracy': [0.7442202568054199,\n",
              "  0.7418511509895325,\n",
              "  0.7405849099159241,\n",
              "  0.739482045173645,\n",
              "  0.7329875230789185,\n",
              "  0.7426272630691528,\n",
              "  0.736336886882782,\n",
              "  0.7389101982116699,\n",
              "  0.7392778396606445,\n",
              "  0.7445878386497498,\n",
              "  0.7446695566177368],\n",
              " 'val_loss': [0.4828853905200958,\n",
              "  0.466174840927124,\n",
              "  0.46810203790664673,\n",
              "  0.4806303381919861,\n",
              "  0.47010451555252075,\n",
              "  0.4628729522228241,\n",
              "  0.4953773021697998,\n",
              "  0.5302706956863403,\n",
              "  0.4848692715167999,\n",
              "  0.4751489460468292,\n",
              "  0.4701392948627472]}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "GpjA3rT8pGPF",
        "outputId": "4cbd3dca-5ad8-4b9c-b8a1-a29ea4dcfdd1"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "sns.lineplot(x=np.arange(len(history.history['accuracy'])), y=history.history['accuracy'], label='accuracy')\n",
        "sns.lineplot(x=np.arange(len(history.history['accuracy'])), y=history.history['loss'], label='loss')\n",
        "sns.lineplot(x=np.arange(len(history.history['accuracy'])), y=history.history['val_accuracy'], label='val_accuracy')\n",
        "sns.lineplot(x=np.arange(len(history.history['accuracy'])), y=history.history['val_loss'], label='val_loss')\n",
        "plt.title('Learning history')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Property measure')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PvoGH4GrXRw"
      },
      "source": [
        "sample = np.array(X_train.iloc[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml6NtD3IsWqa",
        "outputId": "d828110e-979f-4de2-f634-fe32107e2b78"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnPSiAsVspOE",
        "outputId": "14eeb53f-b165-4c88-9472-6d7ab1534734"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2RmH_Isb0t",
        "outputId": "14e6656c-241f-4188-9dae-9e4929dfeb07"
      },
      "source": [
        "df['round_winner'].head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    CT\n",
              "1    CT\n",
              "2    CT\n",
              "3    CT\n",
              "4    CT\n",
              "Name: round_winner, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGcBfkJJsgTW",
        "outputId": "eb15febf-f5e1-4c06-b55b-3e9db0f483e2"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'T', '1': 'CT'}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTmZRXc1rvBl",
        "outputId": "8b782287-c0f0-4945-8025-f6d43d40b2a5"
      },
      "source": [
        "sample.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96,)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ97czSgoliI",
        "outputId": "b536ae67-abb0-481f-cb34-cd4bf1feb27f"
      },
      "source": [
        "prediction = model.predict(np.expand_dims(sample, 0))\n",
        "print([f'{i}: {j}' for i, j in zip(labels.values(), prediction[0])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CT: 0.5672023892402649', 'T: 0.4327976405620575']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TPrFYuEuAL-"
      },
      "source": [
        "# Перенос обучения с модели MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhm_7l5r1mg",
        "outputId": "56daa945-3798-4365-9bca-ae81beb99504"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ_3afcM3VwT",
        "outputId": "bfcc1633-f1f9-4991-d8b7-0ff3a7e80555"
      },
      "source": [
        "!kaggle datasets download -d gpiosenka/balls-image-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading balls-image-classification.zip to /content\n",
            " 95% 188M/198M [00:06<00:00, 23.7MB/s]\n",
            "100% 198M/198M [00:06<00:00, 30.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FjnJsdi3rKH"
      },
      "source": [
        "!unzip -q balls-image-classification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ4iyh8H3xLi"
      },
      "source": [
        "df = pd.read_csv('balls/balls.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "p_yUwRsm4M-7",
        "outputId": "2356bd13-56f9-4c78-8c39-5cadc17b860b"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "      <th>data set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3100</td>\n",
              "      <td>3100</td>\n",
              "      <td>3100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3100</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>train/eyeballs/076.jpg</td>\n",
              "      <td>cannon ball</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "      <td>2860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     filepaths       labels data set\n",
              "count                     3100         3100     3100\n",
              "unique                    3100           24        3\n",
              "top     train/eyeballs/076.jpg  cannon ball    train\n",
              "freq                         1          193     2860"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSgtJHHU4RNV",
        "outputId": "9a8f709f-fa65-4c6d-eff4-59533afb5211"
      },
      "source": [
        "df.isna().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "filepaths    False\n",
              "labels       False\n",
              "data set     False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7EADbEm43U2"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4rhx_nU45xS"
      },
      "source": [
        "im = Image.open('balls/train/eyeballs/076.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPwDjb-Z5GEl",
        "outputId": "dbabf802-e51b-489b-9095-f0378add7d45"
      },
      "source": [
        "im.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmF2Vh265LBq"
      },
      "source": [
        "IMAGE_SIZE = (224, 224, 3)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "STEPS_PER_EPOCH = 100\n",
        "NUM_CLASSES = df['labels'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3_ssZt34yz6"
      },
      "source": [
        "base_model = MobileNetV2(input_shape=IMAGE_SIZE, include_top=False, pooling='avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nqVCabY5oZ_"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBj7TzZJ5gjG"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYAyFVbo5tP9"
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(tensorflow.keras.layers.Flatten())\n",
        "model.add(Dense(256, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL0xYiOT6UfS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQL4Ez172aL"
      },
      "source": [
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=10, width_shift_range=0.2,\n",
        "    height_shift_range=0.2, zoom_range=0.3,\n",
        "    channel_shift_range=0.1, horizontal_flip=True,\n",
        "    vertical_flip=True, rescale=1. / 255.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzP-A2AT9bNN",
        "outputId": "32b45a7a-7520-4780-842b-61a4714900d3"
      },
      "source": [
        "train_data = image_generator.flow_from_directory(\n",
        "    'balls/train', target_size=(IMAGE_SIZE[0], IMAGE_SIZE[0]),\n",
        "    shuffle=False, batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_data = image_generator.flow_from_directory(\n",
        "    'balls/valid', target_size=(IMAGE_SIZE[0], IMAGE_SIZE[0]),\n",
        "    shuffle=False, batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_data = image_generator.flow_from_directory(\n",
        "    'balls/test', target_size=(IMAGE_SIZE[0], IMAGE_SIZE[0]),\n",
        "    shuffle=False, batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2860 images belonging to 24 classes.\n",
            "Found 120 images belonging to 24 classes.\n",
            "Found 120 images belonging to 24 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3dFdkdMAE3i"
      },
      "source": [
        "train_bottleneck_features = base_model.predict(train_data, batch_size=BATCH_SIZE)\n",
        "np.save(open('train_bottleneck_features.npy', 'wb'), train_bottleneck_features)\n",
        "\n",
        "val_bottleneck_features = base_model.predict(val_data, batch_size=BATCH_SIZE)\n",
        "np.save(open('val_bottleneck_features.npy', 'wb'), train_bottleneck_features)\n",
        "\n",
        "test_bottleneck_features = base_model.predict(test_data, batch_size=BATCH_SIZE)\n",
        "np.save(open('test_bottleneck_features.npy', 'wb'), train_bottleneck_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoFmofflNUhN"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(tensorflow.keras.layers.Flatten())\n",
        "model.add(Dense(256, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', input_shape=base_model.output.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1OYzdS8NmO5"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lUVbXHcN4Zo",
        "outputId": "34502052-dcc4-494a-b9e1-ad8ef6ce8291"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    train_data, batch_size=BATCH_SIZE, epochs=EPOCHS, #steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    callbacks=[\n",
        "               EarlyStopping(min_delta=1e-2, patience=10, restore_best_weights=True),\n",
        "               ModelCheckpoint('transfer_1.h5', save_best_only=True)\n",
        "    ],\n",
        "    validation_data=val_data, shuffle=True, validation_batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 4.1530 - accuracy: 0.0423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/45 [==============================] - 46s 917ms/step - loss: 4.1530 - accuracy: 0.0423 - val_loss: 2.6457 - val_accuracy: 0.3000\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 39s 873ms/step - loss: 3.6310 - accuracy: 0.0888 - val_loss: 2.2776 - val_accuracy: 0.4583\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 39s 872ms/step - loss: 3.4480 - accuracy: 0.1182 - val_loss: 2.0860 - val_accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 3.3186 - accuracy: 0.1462 - val_loss: 1.8106 - val_accuracy: 0.5583\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 40s 880ms/step - loss: 3.2137 - accuracy: 0.1573 - val_loss: 1.5914 - val_accuracy: 0.6250\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 39s 867ms/step - loss: 3.1138 - accuracy: 0.2035 - val_loss: 1.6184 - val_accuracy: 0.5750\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 40s 880ms/step - loss: 3.0314 - accuracy: 0.1955 - val_loss: 1.5504 - val_accuracy: 0.5583\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 39s 874ms/step - loss: 2.9753 - accuracy: 0.2266 - val_loss: 1.3273 - val_accuracy: 0.6833\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 39s 871ms/step - loss: 2.9349 - accuracy: 0.2647 - val_loss: 1.2730 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 39s 862ms/step - loss: 2.8560 - accuracy: 0.2794 - val_loss: 1.3532 - val_accuracy: 0.6667\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 40s 877ms/step - loss: 2.8244 - accuracy: 0.2762 - val_loss: 1.2463 - val_accuracy: 0.6750\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 39s 858ms/step - loss: 2.7802 - accuracy: 0.2923 - val_loss: 1.2506 - val_accuracy: 0.6750\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 39s 860ms/step - loss: 2.7485 - accuracy: 0.3245 - val_loss: 1.3440 - val_accuracy: 0.7333\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 39s 864ms/step - loss: 2.7384 - accuracy: 0.3066 - val_loss: 1.3303 - val_accuracy: 0.6833\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 39s 859ms/step - loss: 2.6979 - accuracy: 0.3280 - val_loss: 1.4205 - val_accuracy: 0.5750\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 39s 856ms/step - loss: 2.6666 - accuracy: 0.3399 - val_loss: 1.3242 - val_accuracy: 0.6333\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 39s 862ms/step - loss: 2.6367 - accuracy: 0.3469 - val_loss: 1.3992 - val_accuracy: 0.6583\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 39s 858ms/step - loss: 2.5882 - accuracy: 0.3685 - val_loss: 1.2587 - val_accuracy: 0.6833\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 39s 859ms/step - loss: 2.5614 - accuracy: 0.3818 - val_loss: 1.4157 - val_accuracy: 0.6417\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 39s 858ms/step - loss: 2.5818 - accuracy: 0.3685 - val_loss: 1.4808 - val_accuracy: 0.6083\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 39s 860ms/step - loss: 2.5199 - accuracy: 0.3899 - val_loss: 1.3693 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D48lH56eOo17",
        "outputId": "8a540e4b-f943-4b69-9228-4ae0e679105b"
      },
      "source": [
        "model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 736ms/step - loss: 1.0626 - accuracy: 0.7583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0626314878463745, 0.7583333253860474]"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJtxOSu3Wcvf"
      },
      "source": [
        "for l in base_model.layers[-3:]:\n",
        "    l.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IUOJ0pOW1_Q",
        "outputId": "8e990248-9059-494a-cb90-67314f1f31cf"
      },
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_224\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                    )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)              )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                          )                                ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 1280)        0           ['out_relu[0][0]']               \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 2,560\n",
            "Non-trainable params: 2,255,424\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-DeDcXXQlE",
        "outputId": "2eea6e91-d8e6-4b48-9e8e-204bd5e06dfe"
      },
      "source": [
        "# model.compile(optimizer=Adam(learning_rate=1e-7), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_1 = model.fit(\n",
        "    train_data, batch_size=BATCH_SIZE, epochs=31, initial_epoch=21,\n",
        "    callbacks=[\n",
        "               EarlyStopping(min_delta=1e-4, patience=3, restore_best_weights=True),\n",
        "               ModelCheckpoint('transfer_1.h5', save_best_only=True)\n",
        "    ],\n",
        "    validation_data=val_data, shuffle=True, validation_batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/31\n",
            "45/45 [==============================] - ETA: 0s - loss: 2.8432 - accuracy: 0.2682"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/45 [==============================] - 46s 921ms/step - loss: 2.8432 - accuracy: 0.2682 - val_loss: 1.2727 - val_accuracy: 0.6750\n",
            "Epoch 23/31\n",
            "45/45 [==============================] - 39s 855ms/step - loss: 2.8664 - accuracy: 0.2524 - val_loss: 1.3175 - val_accuracy: 0.6417\n",
            "Epoch 24/31\n",
            "45/45 [==============================] - 39s 857ms/step - loss: 2.8523 - accuracy: 0.2545 - val_loss: 1.3359 - val_accuracy: 0.6000\n",
            "Epoch 25/31\n",
            "45/45 [==============================] - 39s 864ms/step - loss: 2.8600 - accuracy: 0.2517 - val_loss: 1.3687 - val_accuracy: 0.6750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bYvp0sIYcMK",
        "outputId": "b3427091-82c3-40a9-fd94-e56c1d174095"
      },
      "source": [
        "model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 740ms/step - loss: 1.1707 - accuracy: 0.7750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.170738935470581, 0.7749999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6NmKT7cY4Mv",
        "outputId": "6f44eaa1-98c7-4eb1-bc8d-9e7e851ef9e4"
      },
      "source": [
        "image_gen = ImageDataGenerator(\n",
        "    rotation_range=10, width_shift_range=0.2,\n",
        "    height_shift_range=0.2, zoom_range=0.3,\n",
        "    channel_shift_range=0.1, horizontal_flip=True,\n",
        "    vertical_flip=True, rescale=1. / 255.\n",
        ")\n",
        "\n",
        "test_aug = image_generator.flow_from_directory(\n",
        "    'balls/train', target_size=(IMAGE_SIZE[0], IMAGE_SIZE[0]),\n",
        "    shuffle=False, batch_size=BATCH_SIZE, save_to_dir='train', save_prefix='N'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2860 images belonging to 24 classes.\n"
          ]
        }
      ]
    }
  ]
}